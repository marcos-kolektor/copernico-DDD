application {
  api {
    host = "0.0.0.0"
    port = 8080
    port = ${?API_PORT}
    hello-message = "Ameno Arditis!"
  }
}

akka {
  persistence {
    journal.plugin =  "inmemory-journal" # "cassandra-journal" # 
    snapshot-store.plugin =  "inmemory-snapshot-store" # "cassandra-snapshot-store" #  
  }


  coordinated-shutdown.exit-jvm = on

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
    warn-about-java-serializer-usage = on
    allow-java-serialization = off

    # TODO use: Avro - Protobuff - Thrift
    serializers {
      kryo = "com.twitter.chill.akka.AkkaSerializer"
    }
    serialization-bindings {
      "java.io.Serializable" = kryo
      "java.lang.Throwable" = kryo
    }
  }

  remote {
    log-remote-lifecycle-events = on # this could be turned off

    artery {
      enabled = on
      transport = tcp
      canonical.hostname = "localhost"
      canonical.hostname = ${?HOSTNAME}
      canonical.port = 2551
      canonical.port = ${?PORT}
    }
  }

  cluster {
    log-info = off
    use-dispatcher = cluster-dispatcher
    min-nr-of-members = 1

    failure-detector {
      # implementation-class = "akka.remote.PhiAccrualFailureDetector"
      heartbeat-interval = 5 s
      threshold = 12.0
      max-sample-size = 1000
      min-std-deviation = 400 ms
      acceptable-heartbeat-pause = 11 s
      monitored-by-nr-of-members = 3
      expected-response-after = 2 s
    }

    auto-discovery = off
    #seed-nodes = []
    seed-nodes = ["akka://ClusterArditi@localhost:2551"]
    seed-nodes = ${?SEED_NODES}
    shutdown-after-unsuccessful-join-seed-nodes = 30s
  }

  # SBR
  cluster.downing-provider-class = "tanukki.akka.cluster.autodown.MajorityLeaderAutoDowning"
  custom-downing {
    stable-after = 10s

    majority-leader-auto-downing {
      majority-member-role = ""
      down-if-in-minority = true
      shutdown-actor-system-on-resolution = true
    }
  }

  io.dns.resolver = async-dns

  management {
    http {
      hostname = "127.0.0.1"
      hostname = ${?HOSTNAME}
      bind-hostname = "0.0.0.0"
      port = 8558
      bind-port = 8558
    }
    cluster.bootstrap {
      new-cluster-enabled = on
      contact-point-discovery {
        port-name = "management"
        protocol = "tcp"
        service-name = "application-dns-internal"
        discovery-method = akka-dns
      }
    }
  }

  loglevel = "INFO"
  loglevel = ${?LOG_LEVEL}
  # By default messages sent to dead letters are logged at info level for the sake of caution
  # After a few messages this logging is turned off, to avoid flooding the logs.
  log-dead-letters = 10 # adjust how many dead letters are logged
  log-dead-letters-during-shutdown = on

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  # filter the log events using the backend configuration logback.xml before they are published to the event bus.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}

cluster-dispatcher {
    type = "Dispatcher"
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 4
    }
}

inmemory-read-journal {
  # Absolute path to the write journal plugin configuration section to get the event adapters from
  write-plugin = "inmemory-journal"

  # there are two modes; sequence or uuid. If set to "sequence" and NoOffset will be requested, then
  # the query will return Sequence offset types. If set to "uuid" and NoOffset will be requested, then
  # the query will return TimeBasedUUID offset types. When the query is called with Sequence then
  # the query will return Sequence offset types and if the query is called with TimeBasedUUID types then
  # the query will return TimeBasedUUID offset types.
  offset-mode = "sequence"

  # ask timeout on Futures
  ask-timeout = "10s"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "100ms"

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = "100"
}



event-processor {
  id = "event-processor"           // type name of sharded event processor
  keep-alive-interval = 2 seconds  // event-processors ping interval
  tag-prefix = "tag"               // even processor tag prefix
  parallelism = 4                  // number of event processors
}
switch {
  id = "switch-processor"          // type name of sharded write model
  shard-count = 20

}
